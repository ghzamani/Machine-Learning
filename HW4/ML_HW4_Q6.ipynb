{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "columns = ['target', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "train_data = pd.read_csv('adult.train.10k.discrete', header=None)\n",
        "train_data.columns = columns\n",
        "\n",
        "for col in columns:\n",
        "    train_data[col] = train_data[col].str.strip()\n",
        "X_train = train_data.iloc[:, 1:]\n",
        "y_train = train_data.iloc[:, 0]\n",
        "\n",
        "test_data = pd.read_csv('adult.test.10k.discrete', header=None)\n",
        "test_data.columns = columns\n",
        "\n",
        "for col in columns:\n",
        "    test_data[col] = test_data[col].str.strip()\n",
        "X_test = test_data.iloc[:, 1:]\n",
        "y_test = test_data.iloc[:, 0]"
      ],
      "metadata": {
        "id": "QPCtlJsviueK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, value=None, feature=None, children=None):\n",
        "        self.value = value\n",
        "        self.feature = feature\n",
        "        self.children = children\n",
        "\n",
        "\n",
        "def calculate_entropy(X):\n",
        "    # H(S) = - sigma(p*log(p))\n",
        "    e = 0\n",
        "    labels = X.unique()\n",
        "    for l in labels:\n",
        "        p = len(X[X==l]) / len(X)\n",
        "        e -= p * np.log2(p) if p > 0 else 0\n",
        "    return e\n",
        "\n",
        "\n",
        "def calculate_gain(X, y, feature):\n",
        "    total_entropy = calculate_entropy(y)\n",
        "    conditional_entropy = 0\n",
        "\n",
        "    unique_values = X[feature].unique()\n",
        "    for value in unique_values:\n",
        "        # find all rows with the specific value\n",
        "        subset = X[X[feature]==value]\n",
        "        subset_labels = y[X[feature]==value]\n",
        "        if not subset.empty:\n",
        "            e = calculate_entropy(subset_labels)\n",
        "            conditional_entropy += e * len(subset)/len(X)\n",
        "\n",
        "    return total_entropy - conditional_entropy\n",
        "\n",
        "\n",
        "def find_most_informative(X, y, features):\n",
        "    most_gain = -float(\"inf\")\n",
        "    best_feature = None\n",
        "\n",
        "    for feature in features:\n",
        "        g = calculate_gain(X, y, feature)\n",
        "        if g > most_gain:\n",
        "            best_feature = feature\n",
        "            most_gain = g\n",
        "\n",
        "    return best_feature\n",
        "\n",
        "def most_common_class(y):\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    idx =  np.argmax(counts)\n",
        "    return classes[idx]\n",
        "\n",
        "def build_tree(X, y, features_left):\n",
        "\n",
        "    # base case\n",
        "    if len(y.unique()) == 1:\n",
        "        return Node(value=y.iloc[0])\n",
        "\n",
        "    if len(features_left) == 0 or len(X) == 0:\n",
        "        return Node(value=most_common_class(y))\n",
        "\n",
        "    best_feature = find_most_informative(X, y, features_left)\n",
        "    unique_values = X[best_feature].unique()\n",
        "\n",
        "    children = {}\n",
        "    for val in unique_values:\n",
        "        # find all rows which their feature value is 'val'\n",
        "        subset = X[X[best_feature]==val]\n",
        "        labels = y[X[best_feature]==val]\n",
        "        if not subset.empty:\n",
        "            new_features = [f for f in features_left if f != best_feature]\n",
        "            children[val] = build_tree(subset, labels, new_features)\n",
        "\n",
        "    return Node(feature=best_feature, children=children)\n",
        "\n",
        "def predict(tree, data):\n",
        "    try:\n",
        "        if tree.value:\n",
        "            return tree.value\n",
        "\n",
        "        feature = tree.feature\n",
        "        value = data[feature]\n",
        "        return predict(tree.children[value], data)\n",
        "\n",
        "    except:\n",
        "        return '<=50K'"
      ],
      "metadata": {
        "id": "At2pfNnG3Vwy"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = build_tree(X_train, y_train, list(X_train.columns))"
      ],
      "metadata": {
        "id": "1YWuO5PPLqIW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "preds_train = []\n",
        "for i in range(len(X_train)):\n",
        "    preds_train.append(predict(root, X_train.iloc[i]))\n",
        "\n",
        "print(accuracy_score(y_train, preds_train))\n",
        "print(classification_report(y_train, preds_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1wLEjtZbVOC",
        "outputId": "c61417cb-e215-4ffd-be66-1b7bb05d596a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.90      0.94      0.92      7550\n",
            "        >50K       0.79      0.67      0.73      2450\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.84      0.81      0.82     10000\n",
            "weighted avg       0.87      0.88      0.87     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_test = []\n",
        "for i in range(len(X_test)):\n",
        "    preds_test.append(predict(root, X_test.iloc[i]))\n",
        "\n",
        "print(accuracy_score(y_test, preds_test))\n",
        "print(classification_report(y_test, preds_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t57RmET6akkE",
        "outputId": "c8372653-68b5-4909-c3c2-fc0da1880c4e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8097\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.85      0.91      0.88      7539\n",
            "        >50K       0.65      0.50      0.56      2461\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.75      0.71      0.72     10000\n",
            "weighted avg       0.80      0.81      0.80     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}